# Performance Test - ComparaÃ§Ã£o de Servidores Web

Este projeto realiza testes de desempenho (performance tests) comparando trÃªs configuraÃ§Ãµes de servidores web:
- **NGINX** (latest)
- **Apache HTTP Server** com MPM Prefork
- **Apache HTTP Server** com MPM Event

## ğŸ“‹ DescriÃ§Ã£o

O projeto utiliza **K6** (ferramenta de teste de carga) para executar testes de stress nos servidores web configurados via Docker Compose. Os testes avaliam mÃ©tricas como throughput (RPS), latÃªncia, uso de CPU e memÃ³ria sob diferentes cargas de trabalho.

## ğŸš€ Funcionalidades

- ExecuÃ§Ã£o automatizada de testes de carga com diferentes nÃ­veis de usuÃ¡rios virtuais (VUs)
- Coleta de mÃ©tricas de desempenho do K6 (RPS, latÃªncia, erros)
- Monitoramento de recursos dos containers (CPU e memÃ³ria)
- AnÃ¡lise e visualizaÃ§Ã£o de resultados atravÃ©s de grÃ¡ficos
- ComparaÃ§Ã£o de desempenho entre diferentes servidores

## ğŸ“¦ PrÃ©-requisitos

Antes de executar o projeto, certifique-se de ter instalado:

- [Docker](https://docs.docker.com/get-docker/) (versÃ£o 20.10 ou superior)
- [Docker Compose](https://docs.docker.com/compose/install/) (versÃ£o 2.0 ou superior)
- [Python 3](https://www.python.org/downloads/) (versÃ£o 3.7 ou superior)
- Bibliotecas Python:
  ```bash
  pip install pandas matplotlib seaborn
  ```

## ğŸ—ï¸ Estrutura do Projeto

```
.
â”œâ”€â”€ docker-compose.yml          # ConfiguraÃ§Ã£o dos containers
â”œâ”€â”€ test.sh                     # Script principal de execuÃ§Ã£o dos testes
â”œâ”€â”€ analyze.py                  # Script de anÃ¡lise e geraÃ§Ã£o de grÃ¡ficos
â”œâ”€â”€ nginx/                      # ConfiguraÃ§Ãµes do NGINX
â”‚   â””â”€â”€ default.conf
â”œâ”€â”€ apache/                     # ConfiguraÃ§Ãµes do Apache
â”‚   â”œâ”€â”€ httpd-prefork.conf
â”‚   â””â”€â”€ httpd-event.conf
â”œâ”€â”€ k6/                         # Scripts de teste K6
â”‚   â””â”€â”€ test.js
â”œâ”€â”€ static/                     # Arquivos estÃ¡ticos servidos
â”‚   â””â”€â”€ file1.txt
â”œâ”€â”€ results-*/                  # DiretÃ³rios com resultados dos testes
â””â”€â”€ plots-all/                  # DiretÃ³rio com grÃ¡ficos gerados
```

## ğŸ”§ ConfiguraÃ§Ã£o

### Servidores Web

Os servidores sÃ£o configurados para servir um arquivo estÃ¡tico (`file1.txt`) de 1000 linhas:

- **NGINX**: Porta 8081
- **Apache Prefork**: Porta 8082
- **Apache Event**: Porta 8083

### ParÃ¢metros de Teste

Os testes sÃ£o configurados no arquivo `test.sh`:

```bash
LOADS=(100 1000 5000 10000)  # NÃºmero de usuÃ¡rios virtuais (VUs)
DURATION="10s"                # DuraÃ§Ã£o de cada teste
```

VocÃª pode ajustar estes valores conforme necessÃ¡rio.

## â–¶ï¸ ExecuÃ§Ã£o

### 1. Executar os Testes

Execute o script principal para iniciar todos os testes:

```bash
./test.sh
```

O script irÃ¡:
1. Iniciar os containers Docker (NGINX, Apache Prefork, Apache Event, K6)
2. Executar testes de carga para cada servidor com diferentes nÃ­veis de VUs
3. Coletar mÃ©tricas de desempenho e uso de recursos
4. Salvar os resultados em um diretÃ³rio `results-<timestamp>/`

### 2. Analisar os Resultados

ApÃ³s a execuÃ§Ã£o dos testes, analise os resultados com o script Python:

```bash
python3 analyze.py
```

Durante a execuÃ§Ã£o, vocÃª serÃ¡ solicitado a escolher:

1. **Tipo de plot**:
   - `1` - Cada execuÃ§Ã£o separada (mostra todas as execuÃ§Ãµes individuais)
   - `2` - MÃ©dia de todas as execuÃ§Ãµes por servidor/carga (recomendado)

2. **Gerar CSV**:
   - `s` - Gera um arquivo CSV com o resumo das mÃ©tricas
   - `n` - NÃ£o gera CSV

### 3. Visualizar os Resultados

Os grÃ¡ficos sÃ£o salvos no diretÃ³rio `plots-all/` com os seguintes arquivos:

- `throughput_vs_load-*.png` - Throughput (RPS) vs Carga
- `latency_vs_load-*.png` - LatÃªncia P95 vs Carga
- `cpu_vs_load-*.png` - Uso de CPU vs Carga
- `mem_vs_load-*.png` - Uso de MemÃ³ria vs Carga

Se optou por gerar o CSV, tambÃ©m encontrarÃ¡:
- `summary-*.csv` - Resumo de todas as mÃ©tricas

## ğŸ“Š MÃ©tricas Coletadas

### K6 Metrics
- **RPS (Requests Per Second)**: Taxa de requisiÃ§Ãµes por segundo
- **LatÃªncia MÃ©dia**: Tempo mÃ©dio de resposta em milissegundos
- **LatÃªncia P95**: 95Âº percentil da latÃªncia
- **Erros**: NÃºmero de requisiÃ§Ãµes falhadas
- **Checks**: ValidaÃ§Ãµes bem-sucedidas

### Docker Stats
- **CPU (%)**: Percentual de uso de CPU do container
- **MemÃ³ria (MB)**: Uso de memÃ³ria RAM do container

## ğŸ› ï¸ CustomizaÃ§Ã£o

### Modificar Carga de Teste

Edite o arquivo `test.sh` e ajuste o array `LOADS`:

```bash
LOADS=(50 100 500 1000 5000)  # Adicione ou remova cargas conforme necessÃ¡rio
DURATION="30s"                 # Ajuste a duraÃ§Ã£o do teste
```

### Modificar Script de Teste K6

Edite o arquivo `k6/test.js` para customizar o comportamento do teste:

```javascript
export default function () {
  const target = __ENV.TARGET || "http://nginx:80/file1.txt";
  let res = http.get(target);
  latency.add(res.timings.duration);
  check(res, { "status is 200": (r) => r.status === 200 });
}
```

### Ajustar ConfiguraÃ§Ãµes dos Servidores

- **NGINX**: Edite `nginx/default.conf`
- **Apache**: Edite `apache/httpd-prefork.conf` ou `apache/httpd-event.conf`

## ğŸ§¹ Limpeza

Para remover os containers apÃ³s os testes:

```bash
docker compose down
```

Para remover tambÃ©m os volumes e redes:

```bash
docker compose down -v
```

## ğŸ“ Notas

- Os testes sÃ£o executados dentro de containers Docker para garantir isolamento
- Cada teste coleta mÃ©tricas em tempo real enquanto o K6 estÃ¡ executando
- Os resultados sÃ£o organizados por timestamp para facilitar comparaÃ§Ãµes histÃ³ricas
- O arquivo `file1.txt` contÃ©m 1000 linhas de texto de teste

## ğŸ¤ Contribuindo

Sinta-se Ã  vontade para:
1. Fazer fork do projeto
2. Criar uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abrir um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto Ã© open source e estÃ¡ disponÃ­vel para uso educacional e profissional.

## ğŸ‘¤ Autor

DevBrunoRafael

---

**Dica**: Para obter resultados mais precisos, execute os testes mÃºltiplas vezes e use a opÃ§Ã£o de mÃ©dia do `analyze.py`.
